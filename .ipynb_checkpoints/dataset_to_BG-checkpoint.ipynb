{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of the dataset into predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from IPython.display import display\n",
    "from pyswip import *\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and validation scenes and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/murali/My Passport/GQA/sceneGraphs/train_sceneGraphs.json\", 'r') as file:\n",
    "    train_scene = json.load(file)\n",
    "\n",
    "with open(\"/media/murali/My Passport/GQA/sceneGraphs/val_sceneGraphs.json\", 'r') as file:\n",
    "    val_scene= json.load(file)\n",
    "    \n",
    "with open(\"/media/murali/My Passport/GQA/questions1.2/train_balanced_questions.json\", 'r') as file:\n",
    "    train_ques = json.load(file)\n",
    "\n",
    "with open(\"/media/murali/My Passport/GQA/questions1.2/val_balanced_questions.json\", \"r\") as file:\n",
    "    val_ques = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerating the Semantic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total semantic operations: 136\n"
     ]
    }
   ],
   "source": [
    "all_sem_ops = []\n",
    "\n",
    "for qkey in train_ques:\n",
    "    question = train_ques[qkey]\n",
    "    sem_ops = question[\"semantic\"]\n",
    "    for sem_op in sem_ops:\n",
    "        all_sem_ops.append(sem_op[\"operation\"])\n",
    "\n",
    "for qkey in val_ques:\n",
    "    question = val_ques[qkey]\n",
    "    sem_ops = question[\"semantic\"]\n",
    "    for sem_op in sem_ops:\n",
    "        all_sem_ops.append(sem_op[\"operation\"])\n",
    "        \n",
    "all_sem_ops = sorted(list(set(all_sem_ops)))\n",
    "\n",
    "print(\"Total semantic operations: {}\".format(len(all_sem_ops)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerating the Objects, Relations and Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects: 1703\n",
      "Number of attributes: 617\n",
      "Number of relations: 310\n"
     ]
    }
   ],
   "source": [
    "all_relations = []\n",
    "all_attributes = []\n",
    "all_objects = []\n",
    "\n",
    "for skey in train_scene:\n",
    "    objects = train_scene[skey][\"objects\"]\n",
    "    for okey in objects:\n",
    "        for relations in objects[okey][\"relations\"]:\n",
    "            all_relations.append(relations[\"name\"])\n",
    "        all_attributes += objects[okey][\"attributes\"]\n",
    "        all_objects.append(objects[okey][\"name\"])\n",
    "        \n",
    "for skey in val_scene:\n",
    "    objects = val_scene[skey][\"objects\"]\n",
    "    for okey in objects:\n",
    "        for relations in objects[okey][\"relations\"]:\n",
    "            all_relations.append(relations[\"name\"])\n",
    "        all_attributes += objects[okey][\"attributes\"]\n",
    "        all_objects.append(objects[okey][\"name\"])\n",
    "\n",
    "all_relations = sorted(list(set(all_relations)))\n",
    "all_attributes = sorted(list(set(all_attributes)))\n",
    "all_objects = sorted(list(set(all_objects)))\n",
    "\n",
    "print( \"Number of objects: {}\\n\\\n",
    "Number of attributes: {}\\n\\\n",
    "Number of relations: {}\".format(len(all_objects), len(all_attributes), len(all_relations)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing all the constants to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./all_objects.txt\", \"w\") as file:\n",
    "    for objects in all_objects:\n",
    "        file.write(objects+\"\\n\")\n",
    "        \n",
    "with open(\"./all_attributes.txt\", \"w\") as file:\n",
    "    for attr in all_attributes:\n",
    "        file.write(attr+\"\\n\")\n",
    "\n",
    "with open(\"./all_relations.txt\", \"w\") as file:\n",
    "    for rel in all_relations:\n",
    "        file.write(rel+\"\\n\")\n",
    "        \n",
    "with open(\"./all_sem_ops.txt\", \"w\") as file:\n",
    "    for ops in all_sem_ops:\n",
    "        file.write(ops+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerating the location and weather constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cloudy', 'dark', 'clear', 'overcast', 'cloudless', 'sunny', 'foggy', 'partly cloudy', 'stormy', 'rainy'}\n",
      "{'indoors', 'outdoors'}\n"
     ]
    }
   ],
   "source": [
    "all_weather = []\n",
    "all_location = []\n",
    "for skey in train_scene:\n",
    "    try:\n",
    "        all_weather.append(train_scene[skey][\"weather\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        all_location.append(train_scene[skey][\"location\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "all_weather = set(all_weather)\n",
    "all_location = set(all_location)\n",
    "print(all_weather)\n",
    "print(all_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Binary questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "different\n",
      "different color\n",
      "different shape\n",
      "exist\n",
      "filter\n",
      "filter activity\n",
      "filter age\n",
      "filter brightness\n",
      "filter cleanliness\n",
      "filter color\n",
      "filter company\n",
      "filter depth\n",
      "filter event\n",
      "filter face expression\n",
      "filter fatness\n",
      "filter flavor\n",
      "filter gender\n",
      "filter hardness\n",
      "filter height\n",
      "filter hposition\n",
      "filter length\n",
      "filter liquid\n",
      "filter material\n",
      "filter opaqness\n",
      "filter orientation\n",
      "filter pattern\n",
      "filter pose\n",
      "filter race\n",
      "filter realism\n",
      "filter room\n",
      "filter shape\n",
      "filter size\n",
      "filter sport\n",
      "filter sportActivity\n",
      "filter state\n",
      "filter thickness\n",
      "filter tone\n",
      "filter vposition\n",
      "filter weather\n",
      "filter weight\n",
      "filter width\n",
      "or\n",
      "relate\n",
      "same\n",
      "same color\n",
      "same material\n",
      "same shape\n",
      "select\n",
      "verify\n",
      "verify activity\n",
      "verify age\n",
      "verify brightness\n",
      "verify cleanliness\n",
      "verify color\n",
      "verify company\n",
      "verify depth\n",
      "verify face expression\n",
      "verify fatness\n",
      "verify flavor\n",
      "verify gender\n",
      "verify hardness\n",
      "verify height\n",
      "verify hposition\n",
      "verify length\n",
      "verify location\n",
      "verify material\n",
      "verify opaqness\n",
      "verify pattern\n",
      "verify place\n",
      "verify pose\n",
      "verify race\n",
      "verify realism\n",
      "verify rel\n",
      "verify room\n",
      "verify shape\n",
      "verify size\n",
      "verify sportActivity\n",
      "verify state\n",
      "verify texture\n",
      "verify thickness\n",
      "verify tone\n",
      "verify type\n",
      "verify vposition\n",
      "verify weather\n",
      "verify weight\n",
      "verify width\n",
      "331898\n"
     ]
    }
   ],
   "source": [
    "binary_ques = {}\n",
    "binary_sem_operations = []\n",
    "for qkey in train_ques:\n",
    "    answer = train_ques[qkey][\"answer\"]\n",
    "    if answer == 'yes' or answer == 'no':\n",
    "        binary_ques[qkey] = train_ques[qkey]\n",
    "        sem_ops = train_ques[qkey][\"semantic\"]\n",
    "        for sem_op in sem_ops:\n",
    "            binary_sem_operations.append(sem_op[\"operation\"])\n",
    "\n",
    "binary_sem_operations = sorted(list(set(binary_sem_operations)))\n",
    "for op in binary_sem_operations:\n",
    "    print(op)\n",
    "\n",
    "print(len(binary_ques))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up constants\n",
    "\n",
    "Here we set up constants for objects, attributes, weather, locations, horizontal and vertical positions. The object, attribute, weather and location constants are sourced from the dataset. We consider (\"left\", \"right\"), (\"top\", \"bottom\") for horizontal position and the vertical position constants respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectsConst = {val: k for k, val in enumerate(all_objects)}\n",
    "attributeConst = {val : k for k, val in enumerate(all_attributes)}\n",
    "weatherConst = {val : k for k, val in enumerate(all_weather)}\n",
    "locationConst = {val : k for k, val in enumerate(all_location)}\n",
    "hposConst = {\"left\" : 0, \"right\" : 1}\n",
    "vposConst = {\"top\" : 0, \"bottom\" : 1, \"middle\" : 2}\n",
    "\n",
    "Constants = {\"O\" : objectsConst, \"A\" : attributeConst, \"W\" : weatherConst, \"L\" : locationConst, \"H\" : hposConst, \"V\" : vposConst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicates and Knowledge base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predicate:\n",
    "    def __init__(self, name, arity, var_types):\n",
    "        self.name = name\n",
    "        self.arity = arity\n",
    "        self.var_types = var_types\n",
    "        \n",
    "    def printPred(self):\n",
    "        print(\"{}(\".format(self.name), end=\"\")\n",
    "        for i in range(self.arity-1):\n",
    "            print(\"{}, \".format(self.var_types[i]), end=\"\")\n",
    "        print(\"{})\".format(self.var_types[-1]))\n",
    "        \n",
    "class knowledgeBase:\n",
    "    def __init__(self, sceneID):\n",
    "        self.sceneID = sceneID\n",
    "        self.predicateList = dict()\n",
    "        self.bg = dict()\n",
    "    \n",
    "    def addPredicate(self, pred):\n",
    "        self.predicateList[pred.name] = pred\n",
    "\n",
    "        \n",
    "    def addBackground(self, bg):\n",
    "        # bg = [\"name\", \"obj1\", \"obj2\"]\n",
    "        try:\n",
    "            if bg[0] == \"weather\" or bg[0] == \"location\" or bg[0] == \"exist\":\n",
    "                self.bg[bg[0]].append((bg[1]))\n",
    "            else:\n",
    "                self.bg[bg[0]].append((bg[1], bg[2]))\n",
    "        except:\n",
    "            if bg[0] == \"weather\" or bg[0] == \"location\" or bg[0] == \"exist\":\n",
    "                self.bg[bg[0]] = [(bg[1])]\n",
    "            else:\n",
    "                self.bg[bg[0]] = [(bg[1], bg[2])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating global predicates and background knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "globalPreds = {\"same\" : predicate(\"same\", 2, [\"A\", \"A\"])}\n",
    "\n",
    "globalKB = knowledgeBase(\"global\")\n",
    "globalKB.addPredicate(globalPreds[\"same\"])\n",
    "\n",
    "for attr in all_attributes:\n",
    "    attrID = attributeConst[attr]\n",
    "    bg = [\"same\", attrID, attrID]\n",
    "    globalKB.addBackground(bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predicates for object relations and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationPreds = {rels: predicate(rels, 2, [\"O\", \"O\"]) for rels in all_relations}\n",
    "attributePreds = {\"attribute\" : predicate(\"attribute\", 2, [\"O\", \"A\"])}\n",
    "objectPreds = {\"object\" : predicate(\"object\", 2, [\"O\", \"O\"])}\n",
    "weatherPreds = {\"weather\" : predicate(\"weather\", 1, [\"W\"])}\n",
    "locationPreds = {\"location\" : predicate(\"location\", 1, [\"L\"])}\n",
    "hposPreds = {\"hpos\" : predicate(\"hpos\", 2, [\"O\", \"H\"])}\n",
    "vposPreds = {\"vpos\" : predicate(\"vpos\", 2, [\"O\", \"V\"])}\n",
    "existPreds = {\"exist\" : predicate(\"exist\", 1, [\"O\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the knowledge base for every scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHPos(xpos, width):\n",
    "    if xpos < width / 2:\n",
    "        return (\"left\")\n",
    "    else:\n",
    "        return (\"right\")\n",
    "\n",
    "def determineVPos(ypos, height):\n",
    "    if ypos < height / 3:\n",
    "        return (\"top\")\n",
    "    elif ypos >= height / 3 and ypos < (2/3)*height:\n",
    "        return (\"middle\")\n",
    "    else:\n",
    "        return (\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSceneData = {}\n",
    "\n",
    "for i, sid in enumerate(train_scene):\n",
    "    height, width = train_scene[sid][\"height\"], train_scene[sid][\"width\"]\n",
    "    sceneKB = knowledgeBase(sid)\n",
    "    try:\n",
    "        weather = train_scene[sid][\"weather\"]\n",
    "        wID = weatherConst[weather]\n",
    "        w_bg = [\"weather\", wID]\n",
    "        sceneKB.addPredicate(weatherPreds[\"weather\"])\n",
    "        sceneKB.addBackground(w_bg)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        location = train_scene[sid][\"location\"]\n",
    "        lID = locationConst[location]\n",
    "        l_bg = [\"location\", lID]\n",
    "        sceneKB.addPredicate(locationPreds[\"location\"])\n",
    "        sceneKB.addBackground(l_bg)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    objects = train_scene[sid][\"objects\"]\n",
    "    local_map = { okey : [i, objectsConst[objects[okey][\"name\"]]] for i, okey in enumerate(objects) }\n",
    "    local_map[\"null\"] = [len(objects), \"null\"]\n",
    "    for okey in objects:\n",
    "        obj1ID = local_map[okey][0]\n",
    "        objName = local_map[okey][1]\n",
    "        sceneKB.addPredicate(objectPreds[\"object\"])\n",
    "        sceneKB.addBackground([\"object\", obj1ID, objName])\n",
    "        \n",
    "        x, y = objects[okey][\"x\"], objects[okey][\"y\"]\n",
    "        hpos = hposConst[determineHPos(x, width)]\n",
    "        vpos = vposConst[determineVPos(y, height)]\n",
    "        \n",
    "        o_bg = [\"exist\", obj1ID]\n",
    "        sceneKB.addPredicate(existPreds[\"exist\"])\n",
    "        sceneKB.addBackground(o_bg)\n",
    "        \n",
    "        h_bg = [\"hpos\", obj1ID, hpos]\n",
    "        v_bg = [\"vpos\", obj1ID, vpos]\n",
    "        sceneKB.addPredicate(vposPreds[\"vpos\"])\n",
    "        sceneKB.addBackground(v_bg)\n",
    "        sceneKB.addPredicate(hposPreds[\"hpos\"])\n",
    "        sceneKB.addBackground(h_bg)\n",
    "        \n",
    "        for attr in objects[okey][\"attributes\"]:\n",
    "            attrID = attributeConst[attr]\n",
    "            bg = [\"attribute\", obj1ID, attrID]\n",
    "            sceneKB.addPredicate(attributePreds[\"attribute\"])\n",
    "            sceneKB.addBackground(bg)\n",
    "        \n",
    "        for relation in objects[okey][\"relations\"]:\n",
    "            obj2ID = local_map[relation[\"object\"]][0]\n",
    "            bg = [relation[\"name\"].replace(\" \", \"_\"), obj1ID, obj2ID]\n",
    "            sceneKB.addPredicate(relationPreds[relation[\"name\"]])\n",
    "            sceneKB.addBackground(bg)\n",
    "    \n",
    "    trainSceneData[sid] = {\"KB\" : sceneKB, \"local map\" : local_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample binary questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091333\n",
      "Are there either flags or books?\n",
      "select: flag (983557)->exist: ? [0]->select: book (-) ->exist: ? [2]->or:  [1, 3]\n",
      "Answer: yes\n",
      "03616644\n",
      "Are there either any tea kettles or containers?\n",
      "select: container (-)->exist: ? [0]->select: tea kettle (-) ->exist: ? [2]->or:  [1, 3]\n",
      "Answer: no\n",
      "02275312\n",
      "Do you see animals to the right of the grazing animal on the grass?\n",
      "select: grass (1830805)->relate: animal,on,s (1708132) [0]->filter: grazing [1]->relate: animals,to the right of,s (2643211) [2]->exist: ? [3]\n",
      "Answer: no\n",
      "04700826\n",
      "Is the bacon to the left of the cheese in the middle of the photo?\n",
      "select: bacon (3079570)->verify rel: cheese,to the left of,o (2680771) [0]\n",
      "Answer: yes\n",
      "07552336\n",
      "Are there any toilets to the right of the water hose?\n",
      "select: hose (467876)->relate: toilet,to the right of,s (-) [0]->exist: ? [1]\n",
      "Answer: no\n",
      "06570691\n",
      "Do you see vans to the right of the black truck?\n",
      "select: truck (1811853)->filter color: black [0]->relate: van,to the right of,s (-) [1]->exist: ? [2]\n",
      "Answer: no\n",
      "18312823\n",
      "Is the cat small?\n",
      "select: cat (475046)->verify size: small [0]\n",
      "Answer: no\n",
      "13731157\n",
      "Is the cotton towel on the right?\n",
      "select: towel (785891)->filter material: cotton [0]->verify hposition: right [1]\n",
      "Answer: no\n",
      "19283645\n",
      "Is there a red chair or mug?\n",
      "select: mug (2090765)->filter color: red [0]->exist: ? [1]->select: chair (-) ->filter color: red [3]->exist: ? [4]->or:  [2, 5]\n",
      "Answer: yes\n",
      "07591731\n",
      "Are the trousers dark and tan?\n",
      "select: pants (441074)->verify tone: dark [0]->verify color: tan  [0]->and:  [1, 2]\n",
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "random.seed(1056)\n",
    "N_ques = 10\n",
    "sample_ques_key = random.sample(list(binary_ques.keys()), N_ques)\n",
    "for key in sample_ques_key:\n",
    "    print(key)\n",
    "    question = binary_ques[key]\n",
    "    ques = question[\"question\"]\n",
    "    semString = question[\"semanticStr\"]\n",
    "    ans = question[\"answer\"]\n",
    "    print(\"{}\\n{}\\nAnswer: {}\".format(ques, semString, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15867119\n",
      "Are these two animals of the same species?\n",
      "select: animal (1249437,1249430)->same: type [0]\n",
      "051001757\n",
      "Are the two animals of the same type?\n",
      "select: animal (2547536,3608858)->same: type [0]\n",
      "16451217\n",
      "Are both these animals of the same type?\n",
      "select: animal (991976,991990)->same: type [0]\n",
      "0128094\n",
      "Are the animals horses?\n",
      "select: animal (1273572,1273585)->same: type [0]\n",
      "0485991\n",
      "Are the animals cows?\n",
      "select: animal (1049558,1049556,1049562,1049568)->same: type [0]\n",
      "1469734\n",
      "Do these people have the same gender?\n",
      "select: person (1897990,1933021,1876509)->same: gender [0]\n",
      "14459036\n",
      "Do all the animals have the same type?\n",
      "select: animal (2334582,1870044,1944619,2031407)->same: type [0]\n",
      "14513521\n",
      "Are the animals in this scene all of the same species?\n",
      "select: animal (908481,908479,908473,908475,908477)->same: type [0]\n",
      "02884662\n",
      "Are both the animals of the same type?\n",
      "select: animal (1193030,1193048)->same: type [0]\n",
      "04889592\n",
      "Are the people the same gender?\n",
      "select: person (1603439,1603434,1603435,1603444,1603442)->same: gender [0]\n",
      "11187391\n",
      "Are these people male?\n",
      "select: person (4474601,4474584,4474587,4474578,4474579,4234471,4474592)->same: gender [0]\n",
      "08723104\n",
      "Are all these people the same gender?\n",
      "select: person (2869101,3036449,3400907,3021014,3021013)->same: gender [0]\n",
      "041022350\n",
      "Do these people have the same gender?\n",
      "select: person (1824232,1962641)->same: gender [0]\n",
      "03923982\n",
      "Are these people all of the same gender?\n",
      "select: person (3002798,3189867,3189864)->same: gender [0]\n",
      "111057225\n",
      "Are the people all of the same gender?\n",
      "select: person (1334487,1334481,1334482)->same: gender [0]\n",
      "08601287\n",
      "Are these two animals the same species?\n",
      "select: animal (2803645,2613409)->same: type [0]\n",
      "00533339\n",
      "Are the animals sheep?\n",
      "select: animal (390072,390074,390069)->same: type [0]\n",
      "09274162\n",
      "Are these animals the same species?\n",
      "select: animal (4489196,4489194,4489195,4489210,4108070,4478659,4478489,4478465,4108123,4489204,4489240,4108081,4108088,4108358,4478499,4108067,4108063)->same: type [0]\n",
      "19325518\n",
      "Are all these people the same gender?\n",
      "select: person (3049254,3172804,3172805,3608228)->same: gender [0]\n",
      "08590139\n",
      "Do the two people have the same gender?\n",
      "select: person (220989,220992)->same: gender [0]\n",
      "17501269\n",
      "Are all the people the same gender?\n",
      "select: person (1272801)->same: gender [0]\n",
      "0044386\n",
      "Are all the animals dogs?\n",
      "select: animal (3885027,1834067,3885029,1692272,2086652)->same: type [0]\n",
      "18475875\n",
      "Are all these people female?\n",
      "select: person (4164066,4164180,4074914,4164055)->same: gender [0]\n",
      "15446835\n",
      "Do all the people have the same gender?\n",
      "select: person (535912,535914,535920,535933)->same: gender [0]\n",
      "07619096\n",
      "Are the two animals of the same species?\n",
      "select: animal (407959,407969)->same: type [0]\n",
      "17637266\n",
      "Do the two people in the picture have the same gender?\n",
      "select: person (353608,353604)->same: gender [0]\n",
      "04684171\n",
      "Do the people in this picture have the same gender?\n",
      "select: person (1131207,1131203)->same: gender [0]\n",
      "00731833\n",
      "Are the animals the same type?\n",
      "select: animal (924489,924488)->same: type [0]\n",
      "03528243\n",
      "Are both these animals sheep?\n",
      "select: animal (442794,442800)->same: type [0]\n",
      "00661887\n",
      "Are the people of the same gender?\n",
      "select: person (991712,991709)->same: gender [0]\n",
      "13728084\n",
      "Are all these animals of the same species?\n",
      "select: animal (2295356,3191322,3437018,2192091,2805808)->same: type [0]\n",
      "13339137\n",
      "Are all the people female?\n",
      "select: person (816985,816993,816991)->same: gender [0]\n",
      "04463706\n",
      "Are all the animals ostriches?\n",
      "select: animal (2112084,2863536,2863534,2863535)->same: type [0]\n",
      "08960853\n",
      "Are both the people female?\n",
      "select: person (900817,900821)->same: gender [0]\n",
      "1831607\n",
      "Are the people the same gender?\n",
      "select: person (3760597,2435121,2469555)->same: gender [0]\n",
      "07599415\n",
      "Are the two animals the same species?\n",
      "select: animal (3571642,2123504)->same: type [0]\n",
      "18757258\n",
      "Are both these people of the same gender?\n",
      "select: person (4402251,4402255)->same: gender [0]\n",
      "05508447\n",
      "Are these animals all the same species?\n",
      "select: animal (2153778,1972974,1887780,1981670,1887779,1887778,1887777,1887776)->same: type [0]\n",
      "11982550\n",
      "Do the two animals in the picture have the same type?\n",
      "select: animal (683863,683859)->same: type [0]\n",
      "101037976\n",
      "Are the people of the same gender?\n",
      "select: person (1340296,1340310,1340318,1340302)->same: gender [0]\n",
      "09290541\n",
      "Are both the animals in this picture of the same species?\n",
      "select: animal (2403496,2361124)->same: type [0]\n",
      "00774630\n",
      "Are the animals of the same type?\n",
      "select: animal (1571337,1571333)->same: type [0]\n",
      "01954697\n",
      "Are the people all the same gender?\n",
      "select: person (1947633,2492056,2292886)->same: gender [0]\n",
      "14533958\n",
      "Are the people in this photo all the same gender?\n",
      "select: person (2254441,1965963,1662910)->same: gender [0]\n",
      "13342540\n",
      "Are the people of the same gender?\n",
      "select: person (493482,493489,493491)->same: gender [0]\n",
      "00587370\n",
      "Are the people of the same gender?\n",
      "select: person (4154735,4154730)->same: gender [0]\n",
      "18869823\n",
      "Are these animals birds?\n",
      "select: animal (4286011,4286028)->same: type [0]\n",
      "16619164\n",
      "Are the two people the same gender?\n",
      "select: person (725686,725691)->same: gender [0]\n",
      "01396032\n",
      "Are these animals the same type?\n",
      "select: animal (1338598,1338580)->same: type [0]\n",
      "15989984\n",
      "Are the animals all the same type?\n",
      "select: animal (2720683,3470422,3466497,2990138,3293383,3352289,2767895,3501215,3501214,3501216,3501213,3501212)->same: type [0]\n",
      "05374201\n",
      "Are these animals of the same type?\n",
      "select: animal (4390896,4390914,4390846,4390877,4390881,4390867,4390866)->same: type [0]\n",
      "08125137\n",
      "Are the animals all the same species?\n",
      "select: animal (1049610,1049611,1049606)->same: type [0]\n",
      "0982221\n",
      "Are these people female?\n",
      "select: person (1161043,1161047)->same: gender [0]\n",
      "08673894\n",
      "Do all the people have the same gender?\n",
      "select: person (1338975,1338977,1338973)->same: gender [0]\n",
      "02374148\n",
      "Are these animals birds?\n",
      "select: animal (1284662,1284651)->same: type [0]\n",
      "01237500\n",
      "Do these people have the same gender?\n",
      "select: person (2881623,3214667,3471844,3183127,3047288,3182963)->same: gender [0]\n",
      "16748799\n",
      "Are these animals all the same type?\n",
      "select: animal (366062,366052,366048)->same: type [0]\n",
      "00396277\n",
      "Are these people the same gender?\n",
      "select: person (1210444,1210428)->same: gender [0]\n",
      "12206655\n",
      "Are both these animals giraffes?\n",
      "select: animal (2597298,1883726)->same: type [0]\n",
      "09145599\n",
      "Are these animals of the same type?\n",
      "select: animal (3423554,2870262)->same: type [0]\n",
      "15562497\n",
      "Are the people the same gender?\n",
      "select: person (4067933,4095975)->same: gender [0]\n",
      "12230739\n",
      "Are the animals all of the same species?\n",
      "select: animal (697865,697860,697856,697858)->same: type [0]\n",
      "06488569\n",
      "Are all these animals the same type?\n",
      "select: animal (515103,3843690,3843691,3843687,3843686)->same: type [0]\n",
      "08100993\n",
      "Are both these people the same gender?\n",
      "select: person (4209533,4039156)->same: gender [0]\n",
      "04906665\n",
      "Are these people the same gender?\n",
      "select: person (721084,721105,721104)->same: gender [0]\n",
      "101032096\n",
      "Are these animals horses?\n",
      "select: animal (1283604,1283617,1283611)->same: type [0]\n",
      "0398475\n",
      "Are the animals all the same species?\n",
      "select: animal (2246598,1958127,1958125,2701336,1661808,1958128,2017139,1972238,2566815,1962663,3721041,3721043)->same: type [0]\n",
      "141019397\n",
      "Are these two people the same gender?\n",
      "select: person (3906187,2552297)->same: gender [0]\n",
      "15195706\n",
      "Are both the people in this photo of the same gender?\n",
      "select: person (992443,992444)->same: gender [0]\n",
      "02617827\n",
      "Are the people all of the same gender?\n",
      "select: person (1019123,1019121,1019135)->same: gender [0]\n",
      "07751188\n",
      "Are both these animals birds?\n",
      "select: animal (2179279,1812853)->same: type [0]\n",
      "09431618\n",
      "Are all these people of the same gender?\n",
      "select: person (3893207,1668976,1902656)->same: gender [0]\n",
      "18739700\n",
      "Are these animals sheep?\n",
      "select: animal (4153134,4153135,4153085,4153095)->same: type [0]\n",
      "04425304\n",
      "Are both these people the same gender?\n",
      "select: person (2472113,2383061)->same: gender [0]\n",
      "0641293\n",
      "Are these people all of the same gender?\n",
      "select: person (1158358,1158359,1158349)->same: gender [0]\n",
      "17454341\n",
      "Are the people female?\n",
      "select: person (4319124,4445852)->same: gender [0]\n",
      "07232351\n",
      "Are both the animals in the picture the same type?\n",
      "select: animal (3499518,3420828)->same: type [0]\n",
      "11906389\n",
      "Are these animals birds?\n",
      "select: animal (433215,433214,433213,433212)->same: type [0]\n",
      "18683956\n",
      "Are these animals the same species?\n",
      "select: animal (205351,205349)->same: type [0]\n",
      "09106155\n",
      "Are these people of the same gender?\n",
      "select: person (4338748,4338760)->same: gender [0]\n",
      "13292729\n",
      "Do all these animals have the same species?\n",
      "select: animal (4596721,4596719,4596717,4596715)->same: type [0]\n",
      "12145201\n",
      "Are the two animals the same species?\n",
      "select: animal (3494308,3053025)->same: type [0]\n",
      "09946799\n",
      "Are all the animals geese?\n",
      "select: animal (3141279,3119465,3676329,3119469)->same: type [0]\n",
      "18437868\n",
      "Do these two people have the same gender?\n",
      "select: person (819581,819582)->same: gender [0]\n",
      "10191712\n",
      "Are the people the same gender?\n",
      "select: person (593255,593276,593274)->same: gender [0]\n",
      "04904281\n",
      "Are the animals the same type?\n",
      "select: animal (3867444,3867443,3867441,3867436,3867442,3867450)->same: type [0]\n",
      "13402941\n",
      "Are the people of the same gender?\n",
      "select: person (3062916,2809757)->same: gender [0]\n",
      "02303615\n",
      "Are the two people of the same gender?\n",
      "select: person (1547327,1547325)->same: gender [0]\n",
      "03972943\n",
      "Do all these animals have the same type?\n",
      "select: animal (2554298,2677291)->same: type [0]\n",
      "08303867\n",
      "Are these animals all of the same type?\n",
      "select: animal (4130425,3975584,3975589,3975601,3975600,3975597,3975596,3975604,3975593)->same: type [0]\n",
      "01428187\n",
      "Are all the animals the same species?\n",
      "select: animal (2489684,2121721,2025573,2397132)->same: type [0]\n",
      "08570622\n",
      "Are all the animals dogs?\n",
      "select: animal (4390278,4390303,4390291,4390310,4390306,4390299,4390314,4390285,4390287,4390307)->same: type [0]\n",
      "02179581\n",
      "Are the people of the same gender?\n",
      "select: person (4443910,4443911)->same: gender [0]\n",
      "06954963\n",
      "Are the animals in this image of the same type?\n",
      "select: animal (1214031,1214029)->same: type [0]\n",
      "11980066\n",
      "Are both the animals the same type?\n",
      "select: animal (3078449,3465234)->same: type [0]\n",
      "19410969\n",
      "Are both the animals cows?\n",
      "select: animal (3281771,3287398)->same: type [0]\n",
      "19956668\n",
      "Do both the animals in the photo have the same type?\n",
      "select: animal (945579,945587)->same: type [0]\n",
      "09691716\n",
      "Are the animals all the same type?\n",
      "select: animal (4047353,4047334,4047335,4047279,4047285,4047288,4047294)->same: type [0]\n",
      "15563790\n",
      "Are both these animals of the same species?\n",
      "select: animal (173998,173990)->same: type [0]\n",
      "09506463\n",
      "Are both these animals cats?\n",
      "select: animal (528788,528787)->same: type [0]\n"
     ]
    }
   ],
   "source": [
    "not_operation = []\n",
    "all_args = []\n",
    "count = 0\n",
    "op_keys = []\n",
    "for key in binary_ques:\n",
    "    question = binary_ques[key]\n",
    "    semOperations = question[\"semantic\"]\n",
    "    for op in semOperations:\n",
    "        operation = op[\"operation\"]\n",
    "        if operation == \"same\":\n",
    "            print(key)\n",
    "            print(question[\"question\"])\n",
    "            print(question[\"semanticStr\"])\n",
    "            count += 1\n",
    "            op_keys.append(key)\n",
    "            \n",
    "    if count >= 100:\n",
    "        break\n",
    "\n",
    "# all_args = sorted(list(set(all_args)))\n",
    "# print(all_args)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional form to FOL rule\n",
    "\n",
    "The procedure defined below converts a question in its functional form into a FOL clause defining the target predicate. For example, for the question \"Is the grass green and tall?\" having the functional form \"`select: grass (4569011)->verify color: green [0]->verify height: tall  [0]->and:  [1, 2]`\" the FOL clause is as follows:\n",
    "<div align=\"center\">target$(X, Y, Z) \\gets$ attribute$(X, Y)$, attribute$(X, Z)$</div>\n",
    "With the query values being $X = $ grass, $Y = $ green, and $Z =$ tall. For binary question, the following operations are considered:\n",
    "\n",
    "* select\n",
    "* exist\n",
    "* filter\n",
    "* relate\n",
    "* verify\n",
    "    * location\n",
    "    * weather\n",
    "    * hposition\n",
    "    * vposition\n",
    "    * rel\n",
    "    * \"attribute\"\n",
    "* and\n",
    "* or\n",
    "* same\n",
    "* different\n",
    "\n",
    "Each operation stated above has an argument and a dependent variable indicated by the number within the square brackets - in the above example for the operation `verify color` the argument was \"green\" and the dependent variable was \"grass\". Let $A$ and $D$ denote the argument and the dependent variable for a given operation, the order in which there variables are used in the corresponding predicate is dependent on the operation. For all operations but `relate` the order is predicate$(D, A)$ and is the exact opposite for `relate`. For example, consider the excerpt `select: grass (4569011)->verify color: green [0]`, this would translate to `attribute(grass, green)` where `select: man (1163880)->relate: pitcher,next to,s (1163889)` would result in `next_to(pitcher, man)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff2Clause(question, trainSceneData):\n",
    "    imageId = question[\"imageId\"]\n",
    "    sceneData = trainSceneData[imageId]\n",
    "    semOperations = question[\"semantic\"]\n",
    "    local_map = sceneData[\"local map\"]\n",
    "    \n",
    "    target = {\"args\" : None, \"body\" : [], \"query\" : None}\n",
    "    arg_stack = {}\n",
    "    var_dict = {}\n",
    "    \n",
    "    var_map = {i : chr(ord('A') + i) for i in range(26)}\n",
    "    for i in range(26):\n",
    "        var_map[i + 26] = chr(ord('A') + i)*2\n",
    "        var_map[i + 52] = chr(ord('A') + i)*3\n",
    "    v_count = 0\n",
    "    for i, op in enumerate(semOperations):\n",
    "        operation = op[\"operation\"]\n",
    "        dependencies = op[\"dependencies\"]\n",
    "        arguments = op[\"argument\"]\n",
    "    \n",
    "        operation_list = operation.split(\" \")\n",
    "        if operation_list[0] == \"select\":\n",
    "            if len(target[\"body\"]) == 0:\n",
    "                target[\"body\"].append([])\n",
    "                target[\"body\"][-1].append(i)\n",
    "            elif len(target[\"body\"][-1]) > 1:\n",
    "                target[\"body\"].append([])\n",
    "                target[\"body\"][-1].append(i)\n",
    "\n",
    "            args_list = arguments.split(\"(\")\n",
    "            if len(args_list) > 1:\n",
    "                okeys = args_list[1].rstrip(\" \").rstrip(')')\n",
    "                if okeys == \"-\":\n",
    "                    okey = \"null\"\n",
    "                    objID = local_map[okey][0]\n",
    "                    arg_stack[i] = [[args_list[0], var_map[v_count], \"O\"]]\n",
    "                    var_dict[var_map[v_count]] = objID\n",
    "                    v_count += 1\n",
    "                else:\n",
    "                    arg_stack[i] = []\n",
    "                    okeys_list = okeys.split(\",\")\n",
    "                    for okey in okeys_list:\n",
    "                        objID = local_map[okey][0]\n",
    "                        arg_stack[i].append([args_list[0], var_map[v_count], \"O\"])\n",
    "                        var_dict[var_map[v_count]] = objID\n",
    "                        v_count += 1\n",
    "            else:\n",
    "                arg_stack[i] = [\"scene\"]\n",
    "        \n",
    "        elif operation_list[0] == \"exist\":\n",
    "            dep_arg = arg_stack[dependencies[0]][0]\n",
    "            predicate = {\"prefix\" : None, \"pred\" : existPreds[\"exist\"], \"name\": \"exist\", \"var\" : (dep_arg[1])}\n",
    "            target[\"body\"][-1].append(predicate)\n",
    "            target[\"body\"]\n",
    "            target[\"body\"][-1][0] = i\n",
    "        \n",
    "        elif operation_list[0] == \"filter\":\n",
    "            dep_arg = arg_stack[dependencies[0]][0]\n",
    "            arg_stack[i] = [dep_arg] \n",
    "#             arg_list = arguments.split(\" \")\n",
    "            predicate = {\"prefix\" : None}\n",
    "            if arguments[:4] == \"not(\":\n",
    "                attr = arguments.lstrip(\"not\").lstrip(\"(\").rstrip(\")\")\n",
    "                attrID = attributeConst[attr]\n",
    "                predicate[\"prefix\"] = \"not\"\n",
    "                predicate[\"name\"] = \"attribute\"\n",
    "                predicate[\"pred\"] = attributePreds[\"attribute\"]\n",
    "            else:\n",
    "                if len(operation_list) == 2 and operation_list[1] == \"hposition\":\n",
    "                    attr = arguments\n",
    "                    attrID = hposConst[attr]\n",
    "                    predicate[\"name\"] = \"hpos\"\n",
    "                    predicate[\"pred\"] = hposPreds[\"hpos\"]\n",
    "                    \n",
    "                elif len(operation_list) == 2 and operation_list[1] == \"vposition\":\n",
    "                    attr = arguments\n",
    "                    attrID = vposConst[attr]\n",
    "                    predicate[\"name\"] = \"vpos\"\n",
    "                    predicate[\"pred\"] = vposPreds[\"vpos\"]\n",
    "                else:\n",
    "                    attr = arguments\n",
    "                    attrID = attributeConst[attr]\n",
    "                    predicate[\"name\"] = \"attribute\"\n",
    "                    predicate[\"pred\"] = attributePreds[\"attribute\"]\n",
    "\n",
    "            predicate[\"var\"] = (dep_arg[1], var_map[v_count])\n",
    "            target[\"body\"][-1].append(predicate)\n",
    "            target[\"body\"][-1][0] = i\n",
    "            var_dict[var_map[v_count]] = attrID\n",
    "            v_count += 1\n",
    "    \n",
    "        elif operation_list[0] == \"relate\":\n",
    "            dep_arg = arg_stack[dependencies[0]][0]\n",
    "            arg_list = arguments.split(\",\")\n",
    "            relation = arg_list[1]\n",
    "            okey_2 = arg_list[2].split(\" \")[1].lstrip(\"(\").rstrip(\")\")\n",
    "            if okey_2 == \"-\":\n",
    "                okey_2 = \"null\"\n",
    "            objID = local_map[okey_2][0]\n",
    "            arg_stack[i] = [[arg_list[0], var_map[v_count], \"O\"]]\n",
    "            \n",
    "            predicate = {\"prefix\" : None, \"name\" : relation.replace(\" \", \"_\"), \"pred\" : relationPreds[relation], \"var\" : (var_map[v_count] , dep_arg[1])}\n",
    "            target[\"body\"][-1].append(predicate)\n",
    "            target[\"body\"][-1][0] = i\n",
    "            var_dict[var_map[v_count]] = objID\n",
    "            v_count += 1\n",
    "        \n",
    "        elif operation_list[0] == \"verify\":\n",
    "            if len(operation_list) == 2 and operation_list[1] == \"location\":\n",
    "                argID = locationConst[arguments]\n",
    "                predicate = {\"prefix\" : None, \"name\" : \"location\", \"pred\" : locationPreds[\"location\"], \"var\" : (var_map[v_count])}\n",
    "                target[\"body\"][-1].append(predicate)\n",
    "                target[\"body\"][-1][0] = i\n",
    "                var_dict[var_map[v_count]] = argID\n",
    "                v_count += 1\n",
    "        \n",
    "            elif len(operation_list) == 2 and operation_list[1] == \"weather\":\n",
    "                dep_arg = arg_stack[dependencies[0]][0]\n",
    "                if dep_arg == \"scene\":\n",
    "                    argID = weatherConst[arguments]\n",
    "                    predicate = {\"prefix\" : None, \"name\" : \"weather\", \"pred\" : weatherPreds[\"weather\"], \"var\" : (var_map[v_count])}\n",
    "                    target[\"body\"][-1].append(predicate)\n",
    "                    target[\"body\"][-1][0] = i\n",
    "                    var_dict[var_map[v_count]] = argID\n",
    "                    v_count += 1\n",
    "                else:\n",
    "                    argID = attributeConst[arguments.lstrip().rstrip()]\n",
    "                    predicate = {\"prefix\" : None, \"name\" : \"attribute\", \"pred\" : attributePreds[\"attribute\"], \"var\" : (dep_arg[1], var_map[v_count])}\n",
    "                    target[\"body\"][-1].append(predicate)\n",
    "                    target[\"body\"][-1][0] = i\n",
    "                    var_dict[var_map[v_count]] = argID\n",
    "                    v_count += 1\n",
    "                    \n",
    "            elif len(operation_list) == 2 and operation_list[1] == \"hposition\":\n",
    "                dep_arg = arg_stack[dependencies[0]][0]\n",
    "                argID = hposConst[arguments]\n",
    "                predicate = {\"prefix\" : None, \"name\" : \"hpos\", \"pred\" : hposPreds[\"hpos\"], \"var\" : (dep_arg[1], var_map[v_count])}\n",
    "                target[\"body\"][-1].append(predicate)\n",
    "                target[\"body\"][-1][0] = i\n",
    "                var_dict[var_map[v_count]] = argID\n",
    "                v_count += 1\n",
    "                \n",
    "            elif len(operation_list) == 2 and operation_list[1] == \"vposition\":\n",
    "                dep_arg = arg_stack[dependencies[0]][0]\n",
    "                argID = vposConst[arguments]\n",
    "                predicate = {\"prefix\" : None, \"name\" : \"vpos\", \"pred\" : vposPreds[\"vpos\"], \"var\" : (dep_arg[1], var_map[v_count])}\n",
    "                target[\"body\"][-1].append(predicate)\n",
    "                target[\"body\"][-1][0] = i\n",
    "                var_dict[var_map[v_count]] = argID\n",
    "                v_count += 1\n",
    "                    \n",
    "            elif len(operation_list) == 2 and operation_list[1] == \"rel\":\n",
    "                dep_arg = arg_stack[dependencies[0]][0]\n",
    "                arg_list = arguments.split(\",\")\n",
    "                relation = arg_list[1]\n",
    "                okey_2 = arg_list[2].split(\" \")[1].lstrip(\"(\").rstrip(\")\")\n",
    "                if okey_2 == \"-\":\n",
    "                    okey_2 = \"null\"\n",
    "                objID = local_map[okey_2][0]\n",
    "                \n",
    "                predicate = {\"prefix\" : None, \"name\" : relation.replace(\" \",\"_\"), \"pred\" : relationPreds[relation], \"var\" : (dep_arg[1], var_map[v_count])}\n",
    "                target[\"body\"][-1].append(predicate)\n",
    "                target[\"body\"][-1][0] = i\n",
    "                var_dict[var_map[v_count]] = objID\n",
    "                v_count += 1\n",
    "            \n",
    "            elif len(operation_list) == 2 and operation_list[1] == \"place\":\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                dep_arg = arg_stack[dependencies[0]][0]\n",
    "                attr = arguments.lstrip().rstrip()\n",
    "                attrID = attributeConst[attr]\n",
    "                predicate = {\"prefix\" : None, \"name\" : \"attribute\", \"pred\" : attributePreds[\"attribute\"], \"var\" : (dep_arg[1], var_map[v_count])}\n",
    "                target[\"body\"][-1].append(predicate)\n",
    "                target[\"body\"][-1][0] = i\n",
    "                var_dict[var_map[v_count]] = attrID\n",
    "                v_count += 1\n",
    "        \n",
    "        elif operation_list[0] == \"and\":\n",
    "            k = 0\n",
    "            it = 0\n",
    "            body = [dependencies[1]]\n",
    "            while k < len(dependencies) and it < len(target[\"body\"]):\n",
    "                if target[\"body\"][it][0] == dependencies[k]:\n",
    "                    t_body = target[\"body\"].pop(it)\n",
    "                    del t_body[0]\n",
    "                    body += t_body\n",
    "                    k += 1\n",
    "                elif target[\"body\"][it][0] < dependencies[k]:\n",
    "                    it += 1\n",
    "                else:\n",
    "                    k += 1\n",
    "            \n",
    "            target[\"body\"].append(body)\n",
    "        \n",
    "        elif operation_list[0] == \"or\":\n",
    "            assert len(target[\"body\"]) == len(dependencies)\n",
    "            \n",
    "        elif operation_list[0] == \"same\":\n",
    "            if len(operation_list) > 1:\n",
    "                for dep in dependencies:\n",
    "                    dep_arg = arg_stack[dep]\n",
    "                    for da in dep_arg:\n",
    "                        predicate = {\"prefix\" : None, \"name\" : \"attribute\", \"pred\" : attributePreds[\"attribute\"], \"var\" : (da[1], var_map[v_count])}\n",
    "                        target[\"body\"][-1].append(predicate)\n",
    "                        target[\"body\"][-1][0] = i\n",
    "                        var_dict[var_map[v_count]] = \"query\"\n",
    "            else:\n",
    "                for dep in dependencies:\n",
    "                    dep_arg = arg_stack[dep]\n",
    "                    for da in dep_arg:\n",
    "                        predicate = {\"prefix\" : None, \"name\" : \"object\", \"pred\" : objectPreds[\"object\"], \"var\" : (da[1], var_map[v_count])}\n",
    "                        target[\"body\"][-1].append(predicate)\n",
    "                        target[\"body\"][-1][0] = i\n",
    "                        var_dict[var_map[v_count]] = \"query\"\n",
    "                \n",
    "            \n",
    "            v_count += 1\n",
    "            \n",
    "        elif operation_list[0] == \"different\":\n",
    "            diff_var = []\n",
    "            if len(operation_list) > 1:\n",
    "                for dep in dependencies:\n",
    "                    dep_arg = arg_stack[dep]\n",
    "                    for da in dep_arg:\n",
    "                        predicate = {\"prefix\" : None, \"name\" : \"attribute\", \"pred\" : attributePreds[\"attribute\"], \"var\" : (da[1], var_map[v_count])}\n",
    "                        target[\"body\"][-1].append(predicate)\n",
    "                        target[\"body\"][-1][0] = i\n",
    "                        var_dict[var_map[v_count]] = \"query\"\n",
    "                        diff_var.append(var_map[v_count])\n",
    "                        v_count += 1\n",
    "            else:\n",
    "                for dep in dependencies:\n",
    "                    dep_arg = arg_stack[dep]\n",
    "                    for da in dep_arg:\n",
    "                        predicate = {\"prefix\" : None, \"name\" : \"object\", \"pred\" : objectPreds[\"object\"], \"var\" : (da[1], var_map[v_count])}\n",
    "                        target[\"body\"][-1].append(predicate)\n",
    "                        target[\"body\"][-1][0] = i\n",
    "                        var_dict[var_map[v_count]] = \"query\"\n",
    "                        diff_var.append(var_map[v_count])\n",
    "                        v_count += 1\n",
    "            \n",
    "            for i in range(1, len(diff_var)):\n",
    "                predicate = {\"prefix\" : \"not\", \"name\" : \"same\", \"pred\" : globalPreds[\"same\"], \"var\" : (diff_var[i-1], diff_var[i])}\n",
    "                target[\"body\"][-1].append(predicate)\n",
    "                target[\"body\"][-1][0] = i\n",
    "\n",
    "    target[\"args\"] = []\n",
    "    target[\"query\"] = []\n",
    "    for arg in var_dict:\n",
    "        target[\"args\"].append(arg)\n",
    "        target[\"query\"].append(var_dict[arg])\n",
    "\n",
    "    return target\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing function ff2Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': ['A', 'B'], 'body': [[2, {'prefix': 'not', 'name': 'attribute', 'pred': <__main__.predicate object at 0x7f6b7e0f9320>, 'var': ('A', 'B')}, {'prefix': None, 'pred': <__main__.predicate object at 0x7f6c4705ff60>, 'name': 'exist', 'var': 'A'}]], 'query': [0, 338]}\n"
     ]
    }
   ],
   "source": [
    "key = sample_ques_key[-2]\n",
    "question = binary_ques[\"1191591\"]\n",
    "\n",
    "target = ff2Clause(question, trainSceneData)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting binary questions to target predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'outside' 2197\n",
      "'over' 20551\n",
      "'over' 23747\n",
      "'beyond' 28887\n",
      "'looking' 32902\n",
      "'looking' 33064\n",
      "'in the middle of' 36532\n",
      "'looking' 37141\n",
      "'living room' 38355\n",
      "'dining room' 42384\n",
      "'looking' 42743\n",
      "'over' 58888\n",
      "'over' 60879\n",
      "'over' 73295\n",
      "'looking' 74297\n",
      "'over' 88800\n",
      "'over' 90540\n",
      "'in the center of' 91389\n",
      "'in the middle of' 103934\n",
      "'outside' 107547\n",
      "'along' 108612\n",
      "'over' 114786\n",
      "'looking' 116042\n",
      "'over' 117522\n",
      "'looking' 119177\n",
      "'looking' 120382\n",
      "'looking' 120459\n",
      "'outside' 125887\n",
      "'in the middle of' 125922\n",
      "'looking' 131255\n",
      "'looking' 131841\n",
      "'looking' 136188\n",
      "'looking' 141930\n",
      "'looking' 142638\n",
      "'down' 153709\n",
      "'looking' 158634\n",
      "'outside' 173627\n",
      "'looking' 180666\n",
      "'looking' 185086\n",
      "78 187717\n",
      "'looking' 190905\n",
      "'outside' 197432\n",
      "'over' 202085\n",
      "'looking' 208085\n",
      "'looking' 208812\n",
      "'looking' 211021\n",
      "'looking' 214577\n",
      "'looking' 217605\n",
      "'looking' 223016\n",
      "'looking' 225797\n",
      "'beyond' 227067\n",
      "'looking' 230007\n",
      "'outside' 233124\n",
      "78 236776\n",
      "'over' 245722\n",
      "'looking' 246587\n",
      "'over' 254057\n",
      "'over' 255925\n",
      "'looking' 257024\n",
      "'looking' 257330\n",
      "'looking' 261749\n",
      "'looking' 272573\n",
      "'looking' 283712\n",
      "'looking' 285731\n",
      "'looking' 291807\n",
      "'sticking out of' 294503\n",
      "'looking' 299636\n",
      "'outside' 299740\n",
      "'outside' 300368\n",
      "'looking' 301034\n",
      "'looking' 305773\n",
      "'outside' 305941\n",
      "'looking' 309250\n",
      "'looking' 312871\n",
      "'looking' 313745\n",
      "'over' 322365\n",
      "'looking' 326277\n",
      "'over' 327710\n",
      "'looking' 328450\n",
      "'looking' 329787\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "ques_target = {}\n",
    "for i, qkey in enumerate(binary_ques):\n",
    "    try:\n",
    "        question = binary_ques[qkey]\n",
    "        ques_target[qkey] = {\"target\" : ff2Clause(question, trainSceneData), \"answer\" : question[\"answer\"]}\n",
    "    except KeyError as e:\n",
    "        print(e, i)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to prolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryAnswerAlt(question, BG):\n",
    "    bg = BG[\"KB\"].bg    \n",
    "    \n",
    "    with open(\"./sceneData/sceneData.pl\", \"w\") as file:\n",
    "        for pred in bg:\n",
    "            if pred == \"exist\" or pred == \"location\" or pred == \"weather\":\n",
    "                for arg in bg[pred]:\n",
    "                    factStr = pred + \"(\" + str(arg) + \")\"\n",
    "                    file.write(factStr + \".\\n\")\n",
    "#                     print(factStr)\n",
    "            else:\n",
    "                for arg in bg[pred]:\n",
    "                    factStr = pred+ \"(\" + str(arg[0]) + \",\" + str(arg[1]) + \")\"\n",
    "                    file.write(factStr + \".\\n\")\n",
    "#                     print(factStr)\n",
    "        file.write(\"same(X, Y) :- X == Y.\\n\")\n",
    "        head = \"target(\"\n",
    "        for arg in question[\"target\"][\"args\"]:\n",
    "            head += arg + \",\"\n",
    "        target = head[:-1] + ') :- ' \n",
    "\n",
    "        for rule in question[\"target\"][\"body\"]:\n",
    "            rString = \"\"\n",
    "            for predicate in rule[1:]:\n",
    "                p_name = predicate[\"name\"]\n",
    "                pString = p_name + \"(\"\n",
    "                if p_name == \"exist\" or p_name == \"location\" or p_name == \"weather\":\n",
    "                    pString += predicate[\"var\"] + \")\"\n",
    "                else:\n",
    "                    pString += predicate[\"var\"][0] + \",\" + predicate[\"var\"][1] + \")\"\n",
    "\n",
    "                if predicate[\"prefix\"] == \"not\":\n",
    "                    pString = \"not(\" + pString + \")\"\n",
    "\n",
    "                pString += \",\"\n",
    "                rString += pString\n",
    "\n",
    "            target += rString\n",
    "            target = target[:-1] + \" ; \"\n",
    "\n",
    "        target = target[:-2]        \n",
    "        file.write(target + \".\\n\")\n",
    "        \n",
    "        qString = \"target(\"\n",
    "        for qarg in question[\"target\"][\"query\"]:\n",
    "            if qarg == \"query\":\n",
    "                qString += \"_,\"\n",
    "            else:\n",
    "                qString += str(qarg) + \",\"\n",
    "        qString = qString[:-1] + \")\"\n",
    "        file.write(\"go :- \" + qString + \".\")\n",
    "        \n",
    "#         print(target)\n",
    "#         print(qString)\n",
    "        \n",
    "    out = subprocess.run([\"swipl\", \"-s\", \"/media/murali/stuff/projects/explainable_ai/datasets/GQA/sceneData/sceneData.pl\", \"-g\", \"go\", \"-t\", \"halt\"], capture_output=True)\n",
    "    output = out.stderr\n",
    "    if len(output) == 0:\n",
    "        return \"yes\", target, qString\n",
    "    else:\n",
    "        return \"no\", target, qString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 yes yes\n",
      "1 no no\n",
      "2 yes yes\n",
      "3 no no\n",
      "4 yes yes\n",
      "5 yes yes\n",
      "6 yes yes\n",
      "7 yes yes\n",
      "8 no no\n",
      "9 no yes\n",
      "10 no no\n",
      "11 yes yes\n",
      "12 yes yes\n",
      "13 yes yes\n",
      "14 yes yes\n",
      "15 yes yes\n",
      "16 no no\n",
      "17 no no\n",
      "18 yes yes\n",
      "19 no no\n",
      "20 yes no\n",
      "21 yes yes\n",
      "22 no no\n",
      "23 yes yes\n",
      "24 yes yes\n",
      "25 yes yes\n",
      "26 no no\n",
      "27 yes yes\n",
      "28 yes no\n",
      "29 yes yes\n",
      "30 yes yes\n",
      "31 no no\n",
      "32 no no\n",
      "33 yes yes\n",
      "34 yes no\n",
      "35 yes yes\n",
      "36 yes yes\n",
      "37 yes yes\n",
      "38 yes yes\n",
      "39 no no\n",
      "40 no no\n",
      "41 yes yes\n",
      "42 yes yes\n",
      "43 yes yes\n",
      "44 yes yes\n",
      "45 yes yes\n",
      "46 no no\n",
      "47 no no\n",
      "48 yes no\n",
      "49 no no\n",
      "50 no no\n",
      "51 no no\n",
      "52 yes yes\n",
      "53 yes yes\n",
      "54 yes yes\n",
      "55 no no\n",
      "56 yes yes\n",
      "57 no no\n",
      "58 no no\n",
      "59 yes yes\n",
      "60 no no\n",
      "61 yes yes\n",
      "62 yes yes\n",
      "63 no no\n",
      "64 no no\n",
      "65 yes yes\n",
      "66 no no\n",
      "67 no no\n",
      "68 no no\n",
      "69 yes yes\n",
      "70 no no\n",
      "71 no no\n",
      "72 no no\n",
      "73 no no\n",
      "74 no no\n",
      "75 yes yes\n",
      "76 no no\n",
      "77 yes yes\n",
      "78 yes yes\n",
      "79 no no\n",
      "80 yes yes\n",
      "81 yes yes\n",
      "82 yes yes\n",
      "83 yes yes\n",
      "84 yes yes\n",
      "85 no no\n",
      "86 yes yes\n",
      "87 yes yes\n",
      "88 yes yes\n",
      "89 yes yes\n",
      "90 yes yes\n",
      "91 yes yes\n",
      "92 yes yes\n",
      "93 yes yes\n",
      "94 yes yes\n",
      "95 yes yes\n",
      "96 yes yes\n",
      "97 yes yes\n",
      "98 yes yes\n",
      "99 yes yes\n",
      "100 yes yes\n",
      "101 yes yes\n",
      "102 no no\n",
      "103 yes yes\n",
      "104 yes yes\n",
      "105 no no\n",
      "106 no no\n",
      "107 no no\n",
      "108 no no\n",
      "109 no no\n",
      "110 no no\n",
      "111 no no\n",
      "112 yes no\n",
      "113 yes yes\n",
      "114 yes yes\n",
      "115 yes yes\n",
      "116 yes yes\n",
      "117 no no\n",
      "118 no no\n",
      "119 no no\n",
      "120 no no\n",
      "121 no no\n",
      "122 no no\n",
      "123 yes yes\n",
      "124 yes yes\n",
      "125 no yes\n",
      "126 yes yes\n",
      "127 yes yes\n",
      "128 no no\n",
      "129 yes yes\n",
      "130 yes yes\n",
      "131 no no\n",
      "132 yes yes\n",
      "133 yes yes\n",
      "134 yes yes\n",
      "135 yes yes\n",
      "136 yes yes\n",
      "137 no no\n",
      "138 no no\n",
      "139 no no\n",
      "140 no no\n",
      "141 yes yes\n",
      "142 yes yes\n",
      "143 no no\n",
      "144 no no\n",
      "145 yes yes\n",
      "146 yes yes\n",
      "147 yes yes\n",
      "148 yes yes\n",
      "149 no no\n",
      "150 yes yes\n",
      "151 no no\n",
      "152 yes yes\n",
      "153 yes yes\n",
      "154 yes yes\n",
      "155 no yes\n",
      "156 no no\n",
      "157 yes yes\n",
      "158 no no\n",
      "159 yes yes\n",
      "160 yes yes\n",
      "161 no no\n",
      "162 yes yes\n",
      "163 yes yes\n",
      "164 no no\n",
      "165 no no\n",
      "166 yes yes\n",
      "167 no no\n",
      "168 no no\n",
      "169 yes yes\n",
      "170 yes no\n",
      "171 no no\n",
      "172 no no\n",
      "173 no no\n",
      "174 no no\n",
      "175 yes yes\n",
      "176 yes yes\n",
      "177 no no\n",
      "178 no no\n",
      "179 no no\n",
      "180 no no\n",
      "181 no yes\n",
      "182 yes yes\n",
      "183 yes yes\n",
      "184 yes yes\n",
      "185 no no\n",
      "186 yes no\n",
      "187 yes yes\n",
      "188 no no\n",
      "189 no no\n",
      "190 no no\n",
      "191 yes yes\n",
      "192 yes yes\n",
      "193 no no\n",
      "194 yes yes\n",
      "195 no no\n",
      "196 yes yes\n",
      "197 no no\n",
      "198 no no\n",
      "199 yes yes\n",
      "200 no no\n",
      "201 yes yes\n",
      "202 yes yes\n",
      "203 no no\n",
      "204 yes yes\n",
      "205 yes yes\n",
      "206 no no\n",
      "207 no no\n",
      "208 yes yes\n",
      "209 yes yes\n",
      "210 no no\n",
      "211 yes yes\n",
      "212 yes yes\n",
      "213 no no\n",
      "214 no no\n",
      "215 yes yes\n",
      "216 yes yes\n",
      "217 no no\n",
      "218 yes yes\n",
      "219 no no\n",
      "220 yes yes\n",
      "221 no no\n",
      "222 yes yes\n",
      "223 no no\n",
      "224 no no\n",
      "225 no no\n",
      "226 yes yes\n",
      "227 yes no\n",
      "228 no yes\n",
      "229 no no\n",
      "230 no no\n",
      "231 yes yes\n",
      "232 yes yes\n",
      "233 no no\n",
      "234 no no\n",
      "235 yes yes\n",
      "236 no no\n",
      "237 yes yes\n",
      "238 no no\n",
      "239 no no\n",
      "240 yes yes\n",
      "241 no no\n",
      "242 yes yes\n",
      "243 no no\n",
      "244 yes yes\n",
      "245 yes yes\n",
      "246 no no\n",
      "247 yes yes\n",
      "248 no no\n",
      "249 no no\n",
      "250 yes yes\n",
      "251 no no\n",
      "252 no no\n",
      "253 yes yes\n",
      "254 no no\n",
      "255 no no\n",
      "256 yes yes\n",
      "257 yes yes\n",
      "258 yes yes\n",
      "259 yes yes\n",
      "260 yes no\n",
      "261 no no\n",
      "262 yes yes\n",
      "263 yes yes\n",
      "264 no no\n",
      "265 yes yes\n",
      "266 yes no\n",
      "267 no no\n",
      "268 no no\n",
      "269 yes yes\n",
      "270 yes yes\n",
      "271 yes yes\n",
      "272 yes yes\n",
      "273 no no\n",
      "274 yes no\n",
      "275 yes yes\n",
      "276 yes yes\n",
      "277 no no\n",
      "278 yes yes\n",
      "279 no no\n",
      "280 no no\n",
      "281 no no\n",
      "282 yes yes\n",
      "283 no no\n",
      "284 no no\n",
      "285 no no\n",
      "286 no no\n",
      "287 no no\n",
      "288 yes yes\n",
      "289 no no\n",
      "290 yes yes\n",
      "291 no no\n",
      "292 no no\n",
      "293 no no\n",
      "294 no no\n",
      "295 yes yes\n",
      "296 no yes\n",
      "297 yes yes\n",
      "298 yes yes\n",
      "299 no no\n",
      "300 yes no\n",
      "301 no no\n",
      "302 yes yes\n",
      "303 no no\n",
      "304 yes yes\n",
      "305 no no\n",
      "306 yes yes\n",
      "307 no no\n",
      "308 yes yes\n",
      "309 yes yes\n",
      "310 no no\n",
      "311 no no\n",
      "312 yes yes\n",
      "313 yes yes\n",
      "314 no no\n",
      "315 yes yes\n",
      "316 no no\n",
      "317 yes yes\n",
      "318 yes yes\n",
      "319 yes yes\n",
      "320 no no\n",
      "321 no no\n",
      "322 yes yes\n",
      "323 yes yes\n",
      "324 yes yes\n",
      "325 no no\n",
      "326 yes yes\n",
      "327 yes no\n",
      "328 no no\n",
      "329 no no\n",
      "330 no yes\n",
      "331 no no\n",
      "332 no no\n",
      "333 yes yes\n",
      "334 yes yes\n",
      "335 yes yes\n",
      "336 no no\n",
      "337 yes yes\n",
      "338 no no\n",
      "339 no no\n",
      "340 yes yes\n",
      "341 yes yes\n",
      "342 yes yes\n",
      "343 no no\n",
      "344 yes no\n",
      "345 yes no\n",
      "346 no no\n",
      "347 no no\n",
      "348 yes no\n",
      "349 yes yes\n",
      "350 no no\n",
      "351 yes yes\n",
      "352 yes yes\n",
      "353 no no\n",
      "354 yes yes\n",
      "355 no no\n",
      "356 no no\n",
      "357 yes yes\n",
      "358 yes yes\n",
      "359 no no\n",
      "360 no no\n",
      "361 yes yes\n",
      "362 no no\n",
      "363 yes yes\n",
      "364 yes yes\n",
      "365 yes yes\n",
      "366 yes yes\n",
      "367 no no\n",
      "368 no no\n",
      "369 yes yes\n",
      "370 no no\n",
      "371 yes yes\n",
      "372 yes yes\n",
      "373 no yes\n",
      "374 yes yes\n",
      "375 yes yes\n",
      "376 no no\n",
      "377 yes yes\n",
      "378 yes yes\n",
      "379 yes yes\n",
      "380 no no\n",
      "381 no yes\n",
      "382 no no\n",
      "383 yes yes\n",
      "384 yes yes\n",
      "385 yes yes\n",
      "386 yes yes\n",
      "387 no no\n",
      "388 yes yes\n",
      "389 yes yes\n",
      "390 yes yes\n",
      "391 no no\n",
      "392 yes yes\n",
      "393 no no\n",
      "394 yes yes\n",
      "395 yes yes\n",
      "396 yes yes\n",
      "397 yes yes\n",
      "398 no no\n",
      "399 no no\n",
      "400 no no\n",
      "401 no no\n",
      "402 yes yes\n",
      "403 no no\n",
      "404 no no\n",
      "405 no no\n",
      "406 no no\n",
      "407 yes yes\n",
      "408 yes yes\n",
      "409 yes no\n",
      "410 no no\n",
      "411 no no\n",
      "412 yes yes\n",
      "413 yes yes\n",
      "414 no no\n",
      "415 yes yes\n",
      "416 no no\n",
      "417 yes no\n",
      "418 yes yes\n",
      "419 yes yes\n",
      "420 no no\n",
      "421 yes yes\n",
      "422 no no\n",
      "423 yes yes\n",
      "424 yes yes\n",
      "425 no no\n",
      "426 yes yes\n",
      "427 no no\n",
      "428 no no\n",
      "429 no no\n",
      "430 no no\n",
      "431 no no\n",
      "432 no no\n",
      "433 no no\n",
      "434 no no\n",
      "435 yes yes\n",
      "436 yes yes\n",
      "437 no no\n",
      "438 no no\n",
      "439 yes yes\n",
      "440 yes yes\n",
      "441 no no\n",
      "442 no no\n",
      "443 yes yes\n",
      "444 yes yes\n",
      "445 no no\n",
      "446 yes yes\n",
      "447 no no\n",
      "448 no no\n",
      "449 no no\n",
      "450 yes yes\n",
      "451 yes yes\n",
      "452 no no\n",
      "453 yes yes\n",
      "454 yes yes\n",
      "455 no no\n",
      "456 yes yes\n",
      "457 no no\n",
      "458 yes yes\n",
      "459 yes yes\n",
      "460 no no\n",
      "461 no no\n",
      "462 yes yes\n",
      "463 yes yes\n",
      "464 no no\n",
      "465 no no\n",
      "466 yes yes\n",
      "467 yes yes\n",
      "468 no no\n",
      "469 no no\n",
      "470 no no\n",
      "471 no no\n",
      "472 yes yes\n",
      "473 no no\n",
      "474 no no\n",
      "475 yes yes\n",
      "476 no no\n",
      "477 no no\n",
      "478 yes yes\n",
      "479 no no\n",
      "480 yes yes\n",
      "481 no no\n",
      "482 yes yes\n",
      "483 yes yes\n",
      "484 yes yes\n",
      "485 no no\n",
      "486 yes yes\n",
      "487 no no\n",
      "488 yes yes\n",
      "489 yes yes\n",
      "490 no no\n",
      "491 no no\n",
      "492 yes yes\n",
      "493 no no\n",
      "494 no no\n",
      "495 no no\n",
      "496 yes yes\n",
      "497 no no\n",
      "498 yes yes\n",
      "499 yes yes\n",
      "500 yes yes\n",
      "501 no no\n",
      "502 yes yes\n",
      "503 yes yes\n",
      "504 no no\n",
      "505 yes yes\n",
      "506 no no\n",
      "507 no no\n",
      "508 no no\n",
      "509 yes yes\n",
      "510 no no\n",
      "511 no no\n",
      "512 yes yes\n",
      "513 no no\n",
      "514 no no\n",
      "515 yes yes\n",
      "516 yes yes\n",
      "517 yes yes\n",
      "518 yes no\n",
      "519 yes yes\n",
      "520 no no\n",
      "521 yes yes\n",
      "522 yes yes\n",
      "523 no no\n",
      "524 yes yes\n",
      "525 no no\n",
      "526 no no\n",
      "527 yes yes\n",
      "528 no no\n",
      "529 yes yes\n",
      "530 no no\n",
      "531 yes yes\n",
      "532 yes yes\n",
      "533 no no\n",
      "534 yes yes\n",
      "535 no no\n",
      "536 yes yes\n",
      "537 yes yes\n",
      "538 yes yes\n",
      "539 no no\n",
      "540 yes yes\n",
      "541 yes yes\n",
      "542 yes yes\n",
      "543 no no\n",
      "544 yes yes\n",
      "545 yes yes\n",
      "546 no no\n",
      "547 no no\n",
      "548 yes no\n",
      "549 no no\n",
      "550 no no\n",
      "551 yes yes\n",
      "552 no no\n",
      "553 no no\n",
      "554 yes yes\n",
      "555 yes yes\n",
      "556 no no\n",
      "557 no no\n",
      "558 yes yes\n",
      "559 no no\n",
      "560 no no\n",
      "561 yes yes\n",
      "562 yes yes\n",
      "563 no no\n",
      "564 yes yes\n",
      "565 yes yes\n",
      "566 no no\n",
      "567 no no\n",
      "568 no yes\n",
      "569 yes yes\n",
      "570 yes yes\n",
      "571 no no\n",
      "572 yes yes\n",
      "573 yes yes\n",
      "574 yes yes\n",
      "575 yes no\n",
      "576 yes yes\n",
      "577 yes yes\n",
      "578 no no\n",
      "579 yes yes\n",
      "580 no no\n",
      "581 yes yes\n",
      "582 no no\n",
      "583 yes yes\n",
      "584 no no\n",
      "585 yes yes\n",
      "586 no no\n",
      "587 yes yes\n",
      "588 no no\n",
      "589 yes yes\n",
      "590 yes yes\n",
      "591 no no\n",
      "592 yes yes\n",
      "593 no no\n",
      "594 yes yes\n",
      "595 no no\n",
      "596 yes yes\n",
      "597 yes yes\n",
      "598 no no\n",
      "599 no no\n",
      "600 no no\n",
      "601 no no\n",
      "602 no no\n",
      "603 yes yes\n",
      "604 yes yes\n",
      "605 no no\n",
      "606 no no\n",
      "607 yes yes\n",
      "608 yes yes\n",
      "609 yes yes\n",
      "610 yes yes\n",
      "611 yes yes\n",
      "612 yes yes\n",
      "613 yes yes\n",
      "614 yes yes\n",
      "615 yes yes\n",
      "616 no no\n",
      "617 no no\n",
      "618 yes no\n",
      "619 no no\n",
      "620 yes yes\n",
      "621 no no\n",
      "622 yes yes\n",
      "623 no no\n",
      "624 yes yes\n",
      "625 yes yes\n",
      "626 no no\n",
      "627 yes yes\n",
      "628 yes yes\n",
      "629 yes yes\n",
      "630 yes yes\n",
      "631 yes yes\n",
      "632 no no\n",
      "633 no no\n",
      "634 yes yes\n",
      "635 yes no\n",
      "636 no no\n",
      "637 yes yes\n",
      "638 no no\n",
      "639 yes yes\n",
      "640 yes yes\n",
      "641 yes yes\n",
      "642 no no\n",
      "643 yes yes\n",
      "644 yes yes\n",
      "645 no no\n",
      "646 no no\n",
      "647 yes yes\n",
      "648 yes yes\n",
      "649 yes yes\n",
      "650 yes yes\n",
      "651 yes no\n",
      "652 no no\n",
      "653 yes yes\n",
      "654 yes yes\n",
      "655 no no\n",
      "656 no no\n",
      "657 yes yes\n",
      "658 no no\n",
      "659 no no\n",
      "660 no no\n",
      "661 yes yes\n",
      "662 no no\n",
      "663 yes yes\n",
      "664 no no\n",
      "665 yes yes\n",
      "666 yes yes\n",
      "667 no no\n",
      "668 no no\n",
      "669 no no\n",
      "670 yes yes\n",
      "671 no no\n",
      "672 yes yes\n",
      "673 yes yes\n",
      "674 no no\n",
      "675 no no\n",
      "676 no no\n",
      "677 no no\n",
      "678 yes yes\n",
      "679 no no\n",
      "680 no no\n",
      "681 no no\n",
      "682 no no\n",
      "683 no no\n",
      "684 yes yes\n",
      "685 no no\n",
      "686 no no\n",
      "687 no no\n",
      "688 yes yes\n",
      "689 no no\n",
      "690 no no\n",
      "691 yes yes\n",
      "692 yes yes\n",
      "693 no no\n",
      "694 no no\n",
      "695 yes yes\n",
      "696 no no\n",
      "697 no no\n",
      "698 yes yes\n",
      "699 no no\n",
      "700 yes yes\n",
      "701 yes yes\n",
      "702 yes yes\n",
      "703 yes yes\n",
      "704 no no\n",
      "705 yes yes\n",
      "706 no no\n",
      "707 no no\n",
      "708 no no\n",
      "709 no no\n",
      "710 yes yes\n",
      "711 no no\n",
      "712 no no\n",
      "713 yes yes\n",
      "714 no no\n",
      "715 no no\n",
      "716 yes yes\n",
      "717 no no\n",
      "718 no no\n",
      "719 yes no\n",
      "720 yes yes\n",
      "721 yes yes\n",
      "722 no no\n",
      "723 yes yes\n",
      "724 no no\n",
      "725 no no\n",
      "726 no no\n",
      "727 yes yes\n",
      "728 yes yes\n",
      "729 no no\n",
      "730 no no\n",
      "731 no no\n",
      "732 no no\n",
      "733 yes yes\n",
      "734 yes yes\n",
      "735 no no\n",
      "736 no no\n",
      "737 no no\n",
      "738 no no\n",
      "739 no no\n",
      "740 no no\n",
      "741 yes yes\n",
      "742 yes yes\n",
      "743 yes yes\n",
      "744 no no\n",
      "745 no yes\n",
      "746 yes yes\n",
      "747 no no\n",
      "748 yes yes\n",
      "749 no no\n",
      "750 no no\n",
      "751 yes no\n",
      "752 no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753 no no\n",
      "754 no no\n",
      "755 no no\n",
      "756 yes yes\n",
      "757 yes yes\n",
      "758 no no\n",
      "759 yes yes\n",
      "760 yes no\n",
      "761 yes yes\n",
      "762 yes yes\n",
      "763 no no\n",
      "764 no no\n",
      "765 yes yes\n",
      "766 no no\n",
      "767 no no\n",
      "768 no no\n",
      "769 yes no\n",
      "770 yes yes\n",
      "771 yes yes\n",
      "772 no no\n",
      "773 yes yes\n",
      "774 yes yes\n",
      "775 yes no\n",
      "776 no no\n",
      "777 no no\n",
      "778 no no\n",
      "779 yes yes\n",
      "780 no no\n",
      "781 no no\n",
      "782 no no\n",
      "783 no no\n",
      "784 no no\n",
      "785 yes yes\n",
      "786 no no\n",
      "787 yes yes\n",
      "788 no no\n",
      "789 no no\n",
      "790 no no\n",
      "791 yes yes\n",
      "792 no no\n",
      "793 no no\n",
      "794 yes yes\n",
      "795 yes yes\n",
      "796 yes no\n",
      "797 yes yes\n",
      "798 no no\n",
      "799 no yes\n",
      "800 yes yes\n",
      "801 no no\n",
      "802 no no\n",
      "803 yes yes\n",
      "804 no no\n",
      "805 yes yes\n",
      "806 no no\n",
      "807 yes yes\n",
      "808 no no\n",
      "809 yes yes\n",
      "810 yes yes\n",
      "811 yes yes\n",
      "812 no no\n",
      "813 no no\n",
      "814 yes yes\n",
      "815 yes yes\n",
      "816 no no\n",
      "817 no no\n",
      "818 no no\n",
      "819 no no\n",
      "820 no no\n",
      "821 no no\n",
      "822 yes yes\n",
      "823 no no\n",
      "824 yes yes\n",
      "825 no no\n",
      "826 yes yes\n",
      "827 no yes\n",
      "828 no no\n",
      "829 no no\n",
      "830 no yes\n",
      "831 yes yes\n",
      "832 yes yes\n",
      "833 yes yes\n",
      "834 yes yes\n",
      "835 no no\n",
      "836 yes yes\n",
      "837 no no\n",
      "838 no no\n",
      "839 no no\n",
      "840 yes yes\n",
      "841 no no\n",
      "842 yes no\n",
      "843 yes yes\n",
      "844 no no\n",
      "845 yes yes\n",
      "846 yes yes\n",
      "847 yes yes\n",
      "848 yes yes\n",
      "849 yes yes\n",
      "850 no no\n",
      "851 no no\n",
      "852 no no\n",
      "853 no no\n",
      "854 no no\n",
      "855 yes yes\n",
      "856 no no\n",
      "857 no no\n",
      "858 yes yes\n",
      "859 yes yes\n",
      "860 no no\n",
      "861 yes yes\n",
      "862 no no\n",
      "863 no no\n",
      "864 no no\n",
      "865 no no\n",
      "866 no no\n",
      "867 yes yes\n",
      "868 yes yes\n",
      "869 no no\n",
      "870 yes yes\n",
      "871 no no\n",
      "872 no no\n",
      "873 no no\n",
      "874 yes yes\n",
      "875 yes yes\n",
      "876 yes yes\n",
      "877 yes yes\n",
      "878 yes yes\n",
      "879 yes yes\n",
      "880 yes yes\n",
      "881 no no\n",
      "882 no no\n",
      "883 yes yes\n",
      "884 no no\n",
      "885 no no\n",
      "886 yes yes\n",
      "887 no no\n",
      "888 yes yes\n",
      "889 yes yes\n",
      "890 no no\n",
      "891 yes yes\n",
      "892 no no\n",
      "893 yes yes\n",
      "894 yes yes\n",
      "895 yes yes\n",
      "896 no no\n",
      "897 no no\n",
      "898 yes yes\n",
      "899 no no\n",
      "900 yes no\n",
      "901 no no\n",
      "902 no no\n",
      "903 yes yes\n",
      "904 no no\n",
      "905 yes yes\n",
      "906 no no\n",
      "907 no no\n",
      "908 no no\n",
      "909 yes yes\n",
      "910 yes yes\n",
      "911 no no\n",
      "912 yes yes\n",
      "913 no yes\n",
      "914 yes yes\n",
      "915 yes yes\n",
      "916 yes yes\n",
      "917 no no\n",
      "918 no no\n",
      "919 yes yes\n",
      "920 yes yes\n",
      "921 yes yes\n",
      "922 no no\n",
      "923 yes yes\n",
      "924 no no\n",
      "925 yes yes\n",
      "926 yes yes\n",
      "927 no no\n",
      "928 no yes\n",
      "929 no no\n",
      "930 yes yes\n",
      "931 yes yes\n",
      "932 no no\n",
      "933 yes yes\n",
      "934 yes no\n",
      "935 no yes\n",
      "936 no no\n",
      "937 no no\n",
      "938 yes yes\n",
      "939 yes no\n",
      "940 no no\n",
      "941 no no\n",
      "942 yes yes\n",
      "943 no no\n",
      "944 yes yes\n",
      "945 yes yes\n",
      "946 no no\n",
      "947 yes yes\n",
      "948 yes yes\n",
      "949 yes yes\n",
      "950 yes yes\n",
      "951 yes yes\n",
      "952 no no\n",
      "953 yes yes\n",
      "954 no no\n",
      "955 no yes\n",
      "956 yes yes\n",
      "957 no no\n",
      "958 no no\n",
      "959 no no\n",
      "960 yes yes\n",
      "961 no no\n",
      "962 yes yes\n",
      "963 no no\n",
      "964 yes yes\n",
      "965 yes yes\n",
      "966 no no\n",
      "967 no no\n",
      "968 yes yes\n",
      "969 no no\n",
      "970 yes yes\n",
      "971 yes yes\n",
      "972 no no\n",
      "973 no no\n",
      "974 yes yes\n",
      "975 yes yes\n",
      "976 yes yes\n",
      "977 no no\n",
      "978 yes yes\n",
      "979 no no\n",
      "980 no no\n",
      "981 no no\n",
      "982 no no\n",
      "983 no no\n",
      "984 no no\n",
      "985 yes yes\n",
      "986 no no\n",
      "987 yes no\n",
      "988 no no\n",
      "989 no no\n",
      "990 yes yes\n",
      "991 yes yes\n",
      "992 yes yes\n",
      "993 yes yes\n",
      "994 yes yes\n",
      "995 yes yes\n",
      "996 no no\n",
      "997 yes yes\n",
      "998 yes yes\n",
      "999 yes yes\n"
     ]
    }
   ],
   "source": [
    "with open(\"./wrong_ans.txt\", \"w\") as file:\n",
    "\n",
    "    count = 0\n",
    "#     for i, qkey in enumerate(op_keys):\n",
    "#     for i, qkey in enumerate([\"18808141\"]):\n",
    "    for i, qkey in enumerate(ques_target):\n",
    "        question = ques_target[qkey]\n",
    "        imageId = train_ques[qkey][\"imageId\"]\n",
    "        sceneData = trainSceneData[imageId]\n",
    "        p, target, qString = queryAnswerAlt(question, sceneData)\n",
    "        print(i, p, question[\"answer\"])\n",
    "        if p == question[\"answer\"]:\n",
    "            count += 1\n",
    "        else:\n",
    "            file.write(\"{}\\n\".format(i))\n",
    "            file.write(\"Predicted Answer: {}\\tRight Answer: {}\\n\".format(p, question[\"answer\"]))\n",
    "            file.write(\"Question: {}\\n\".format(train_ques[qkey][\"question\"]))\n",
    "            file.write(\"FF      : {}\\n\".format(train_ques[qkey][\"semanticStr\"]))\n",
    "            file.write(target+\"\\n\")\n",
    "            file.write(qString+\"\\n\")\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        if i == 999:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': ['A', 'B', 'C', 'D'], 'body': [[1, {'prefix': None, 'name': 'object', 'pred': <__main__.predicate object at 0x7fe77bc77550>, 'var': ('A', 'D')}, {'prefix': None, 'name': 'object', 'pred': <__main__.predicate object at 0x7fe77bc77550>, 'var': ('B', 'D')}, {'prefix': None, 'name': 'object', 'pred': <__main__.predicate object at 0x7fe77bc77550>, 'var': ('C', 'D')}]], 'query': [4, 10, 16, 'query']} \n",
      "\n",
      "Are the animals sheep? \n",
      "\n",
      "select: animal (390072,390074,390069)->same: type [0] \n",
      "\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "print(question[\"target\"], \"\\n\")\n",
    "print(train_ques[qkey][\"question\"], \"\\n\")\n",
    "print(train_ques[qkey][\"semanticStr\"], \"\\n\")\n",
    "print(train_ques[qkey][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KB': <__main__.knowledgeBase at 0x7fe8ad1330b8>,\n",
       " 'local map': {'390093': [0, 553],\n",
       "  '390094': [1, 960],\n",
       "  '390083': [2, 666],\n",
       "  '390073': [3, 528],\n",
       "  '390072': [4, 802],\n",
       "  '390071': [5, 528],\n",
       "  '390070': [6, 528],\n",
       "  '390077': [7, 813],\n",
       "  '390076': [8, 523],\n",
       "  '390075': [9, 523],\n",
       "  '390074': [10, 802],\n",
       "  '390095': [11, 702],\n",
       "  '390087': [12, 1688],\n",
       "  '390079': [13, 813],\n",
       "  '390078': [14, 813],\n",
       "  '390068': [15, 523],\n",
       "  '390069': [16, 1290],\n",
       "  '390080': [17, 813],\n",
       "  '390092': [18, 554],\n",
       "  'null': [19, 'null']}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sceneData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 bike\n"
     ]
    }
   ],
   "source": [
    "print(\"4\", all_objects[134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 helmet\n"
     ]
    }
   ],
   "source": [
    "print(\"1\", all_objects[714])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Cases\n",
    "\n",
    "#### Convention in the order of arguments for \"relate\" and \"verify rel\"\n",
    "\n",
    "In some cases the functional form doesn't stick to a fixed convention. Consider the question \"Do you see any bookcase to the left of the napkin the cat is to the right of?\", here we have three objects a cat, napkin and a bookcase and we know that the cat is to the right of the napkin. In shothand if we denote this physical relation as napkin--cat and we want to know if bookcase--napkin--cat is true? This induces the following target predicate,\n",
    "<div align=\"center\">target(bookcase, napkin, cat) $\\gets$ to_the_right_of(cat, napkin), to_the_left_of(bookcase, napkin)</div>\n",
    "From the scene graph we encode the relation napking--cat as to_the_right_of(cat, napkin). Looking at the functional form of the question select: cat (1298333)->relate: napkin,to the right of,o (1298346) [0]->relate: bookcase,to the left of,s (1298370) [1]->exist: ? [2], if we stick to the convention we assumed previously then we get\n",
    "<div align=\"center\">target(bookcase, napkin, cat) $\\gets$ to_the_right_of(napkin, cat), to_the_left_of(bookcase, napkin)</div>\n",
    "Which is not what we need! This is not solved even if I switch the convention as that would result in,\n",
    "<div align=\"center\">target(bookcase, napkin, cat) $\\gets$ to_the_right_of(cat, napkin), to_the_left_of(napkin, bookcase)</div>\n",
    "Which is still not what we need indicating that the functional form doesn't follow a fixed convention! So naturally the model predicts the wrong answer. Here I've shown an example for the operation \"relate\" but a similar behavior is observed for \"verify rel\" as well. \n",
    "\n",
    "#### Functional form contains relations not present in the scene graph\n",
    "\n",
    "In few cases the functional form contains relations that aren't contained in the scene graph for the scene. For example, in the question \"Do the man jeans look dark?\" we are trying to query if the color of the jeans the man's wearing is dark?. Looking at the functional form \"select: man (4486961)->relate: jeans,of,s (4486963) [0]->verify color: dark [1]\" we see that the relation \"of\" is used to relate the man and the jeans. But in the scene graph this relation is not present. Instead we have the relation \"wearing\" connecting \"man\" and \"jeans\". Without any background on the relation \"of\", forward chaining results in the wrong answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2402376'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-binary questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ques = {}\n",
    "\n",
    "for qkey in train_ques:\n",
    "    if train_ques[qkey][\"answer\"] not in [\"yes\", \"no\"]:\n",
    "        nb_ques[qkey] = train_ques[qkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 15548375\n",
      "Question: What animal is it?\n",
      "FF: select: animal (325211)->query: name [0]\n",
      "Answer: cat\n",
      "\n",
      "\n",
      "Key: 02239633\n",
      "Question: What is on the cow?\n",
      "FF: select: cow (573466)->relate: _,on,s (573471) [0]->query: name [1]\n",
      "Answer: rope\n",
      "\n",
      "\n",
      "Key: 07178125\n",
      "Question: Which side of the image is the bottle on?\n",
      "FF: select: bottle (2700553)->query: hposition [0]\n",
      "Answer: left\n",
      "\n",
      "\n",
      "Key: 02825521\n",
      "Question: What's the sidewalk made of?\n",
      "FF: select: sidewalk (401287)->query: material [0]\n",
      "Answer: concrete\n",
      "\n",
      "\n",
      "Key: 09457573\n",
      "Question: What's the man sitting on?\n",
      "FF: select: man (312222)->relate: _,sitting on,o (312225) [0]->query: name [1]\n",
      "Answer: ski lift\n",
      "\n",
      "\n",
      "Key: 13443729\n",
      "Question: Which side of the picture is the container on?\n",
      "FF: select: container (3914778)->query: hposition [0]\n",
      "Answer: left\n",
      "\n",
      "\n",
      "Key: 04495788\n",
      "Question: What color are the sneakers?\n",
      "FF: select: sneakers (674710)->query: color [0]\n",
      "Answer: black\n",
      "\n",
      "\n",
      "Key: 19963773\n",
      "Question: What color are the laptops to the left of the guitar?\n",
      "FF: select: guitar (2366283)->relate: laptops,to the left of,s (2450805) [0]->query: color [1]\n",
      "Answer: silver\n",
      "\n",
      "\n",
      "Key: 05304307\n",
      "Question: What is on the home plate?\n",
      "FF: select: home plate (597885)->relate: _,on,s (597901) [0]->query: name [1]\n",
      "Answer: word\n",
      "\n",
      "\n",
      "Key: 02262158\n",
      "Question: Which side of the picture is the black vehicle on?\n",
      "FF: select: vehicle (1798472)->filter color: black [0]->query: hposition [1]\n",
      "Answer: left\n",
      "\n",
      "\n",
      "Key: 11433147\n",
      "Question: Is the blue umbrella in the top or in the bottom?\n",
      "FF: select: umbrella (776337)->filter color: blue [0]->choose vposition: bottom|top [1]\n",
      "Answer: bottom\n",
      "\n",
      "\n",
      "Key: 10883528\n",
      "Question: On which side of the image is the large clock?\n",
      "FF: select: clock (655195)->filter size: large [0]->query: hposition [1]\n",
      "Answer: left\n",
      "\n",
      "\n",
      "Key: 17165677\n",
      "Question: What kind of clothing is white?\n",
      "FF: select: clothing (1136480)->filter color: white [0]->query: name [1]\n",
      "Answer: pants\n",
      "\n",
      "\n",
      "Key: 03192160\n",
      "Question: What is the food that is to the right of the tablecloth?\n",
      "FF: select: tablecloth (4518710)->relate: fast food,to the right of,s (4518682) [0]->query: name [1]\n",
      "Answer: pizza\n",
      "\n",
      "\n",
      "Key: 06120303\n",
      "Question: The blanket to the right of the mattresses is which color?\n",
      "FF: select: mattresses (4518593)->relate: blanket,to the right of,s (4518519) [0]->query: color [1]\n",
      "Answer: pink\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing random non-binary questions\n",
    "random.seed(1024)\n",
    "N_ques = 15\n",
    "random_choice = random.sample(list(nb_ques.keys()), N_ques)\n",
    "\n",
    "for key in random_choice:\n",
    "    print(\"Key: {}\".format(key))\n",
    "    print(\"Question: {}\".format(nb_ques[key][\"question\"]))\n",
    "    print(\"FF: {}\".format(nb_ques[key][\"semanticStr\"]))\n",
    "    print(\"Answer: {}\".format(nb_ques[key][\"answer\"]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "op_keys = []\n",
    "query_args = []\n",
    "sp_ans = []\n",
    "common_ans = []\n",
    "for key in nb_ques:\n",
    "    question = nb_ques[key]\n",
    "    semOperations = question[\"semantic\"]\n",
    "    for op in semOperations:\n",
    "        operation = op[\"operation\"]\n",
    "        if operation == \"query\":\n",
    "#             if op[\"argument\"] == \"None\":\n",
    "#             common_ans.append(question[\"answer\"])\n",
    "            if op[\"argument\"] == \"tone\":\n",
    "                sp_ans.append(question[\"answer\"])\n",
    "\n",
    "#                 print(\"QKey: {}\".format(key))\n",
    "#                 print(\"Image ID: {}\".format(question[\"imageId\"]))\n",
    "#                 print(question[\"question\"])\n",
    "#                 print(question[\"semanticStr\"])\n",
    "#                 print(question[\"answer\"])\n",
    "#                 print(\"\\n\")\n",
    "#                 count += 1\n",
    "#                 op_keys.append(key)\n",
    "            \n",
    "#     if count >= 200:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light\n",
      "taking a picture\n"
     ]
    }
   ],
   "source": [
    "sp_ans = sorted(list(set(sp_ans)))\n",
    "for ans in sp_ans:\n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_args = sorted(list(set(query_args)))\n",
    "with open(\"./query_args.txt\", \"w\") as file:\n",
    "    for args in query_args[8:]:\n",
    "        file.write(args+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
